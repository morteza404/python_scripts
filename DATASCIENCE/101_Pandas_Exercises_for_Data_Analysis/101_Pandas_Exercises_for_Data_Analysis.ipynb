{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How to import pandas and check the version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to create a series from a list, numpy array and dict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "e    3\n",
      "d    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "\n",
    "# Solution\n",
    "ser1 = pd.Series(mylist)\n",
    "ser2 = pd.Series(myarr)\n",
    "ser3 = pd.Series(mydict)\n",
    "print(ser3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How to convert the index of a series into a column of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  0\n",
      "0     a  0\n",
      "1     b  1\n",
      "2     c  2\n",
      "3     e  3\n",
      "4     d  4\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)\n",
    "\n",
    "# Solution\n",
    "df = ser.to_frame().reset_index()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How to combine many series to form a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1  col2\n",
      "0    a     0\n",
      "1    b     1\n",
      "2    c     2\n",
      "3    e     3\n",
      "4    d     4\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "\n",
    "# Solution 1\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "\n",
    "# Solution 2\n",
    "df = pd.DataFrame({'col1': ser1, 'col2': ser2})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How to assign name to the series’ index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    e\n",
       "4    d\n",
       "Name: alphabets, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "\n",
    "# Solution\n",
    "ser.name = 'alphabets'\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. How to get the items of series A not present in series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "# Solution\n",
    "ser1[~ser1.isin(ser2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. How to get the items not common to both series A and series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "5    6\n",
       "6    7\n",
       "7    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "# Solution\n",
    "ser_u = pd.Series(np.union1d(ser1, ser2))  # union\n",
    "ser_i = pd.Series(np.intersect1d(ser1, ser2))  # intersect\n",
    "ser_u[~ser_u.isin(ser_i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25117263,  7.70986507, 10.92259345, 13.36360403, 18.0949083 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "state = np.random.RandomState(100)\n",
    "ser = pd.Series(state.normal(10, 5, 25))\n",
    "\n",
    "# Solution\n",
    "np.percentile(ser, q=[0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. How to get frequency counts of unique items of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    7\n",
       "a    6\n",
       "e    5\n",
       "g    3\n",
       "h    3\n",
       "f    3\n",
       "c    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "\n",
    "# Solution\n",
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 Freq: 3    6\n",
      "4    3\n",
      "1    2\n",
      "2    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     Other\n",
       "1         3\n",
       "2         3\n",
       "3         3\n",
       "4     Other\n",
       "5         4\n",
       "6         3\n",
       "7         4\n",
       "8         3\n",
       "9     Other\n",
       "10        4\n",
       "11        3\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "\n",
    "# Solution\n",
    "print(\"Top 2 Freq:\", ser.value_counts())\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. How to bin a numeric series to 10 groups of equal size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.594089\n",
      "1    0.195615\n",
      "2    0.167082\n",
      "3    0.012975\n",
      "4    0.829469\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    6th\n",
       "1    3rd\n",
       "2    3rd\n",
       "3    1st\n",
       "4    9th\n",
       "dtype: category\n",
       "Categories (10, object): [1st < 2nd < 3rd < 4th ... 7th < 8th < 9th < 10th]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.random(20))\n",
    "print(ser.head())\n",
    "\n",
    "# Solution\n",
    "pd.qcut(ser, q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "        labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. How to convert a numpy array to a dataframe of given shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4\n",
      "0  8  3  5  7  1\n",
      "1  5  4  6  7  3\n",
      "2  2  5  5  7  7\n",
      "3  3  9  3  8  4\n",
      "4  2  5  7  8  1\n",
      "5  6  3  4  4  1\n",
      "6  1  1  5  7  3\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "\n",
    "# Solution\n",
    "df = pd.DataFrame(ser.values.reshape(7,5))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. How to find the positions of numbers that are multiples of 3 from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7\n",
      "1    1\n",
      "2    5\n",
      "3    6\n",
      "4    7\n",
      "5    7\n",
      "6    5\n",
      "dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "ser\n",
    "\n",
    "# Solution\n",
    "print(ser)\n",
    "np.argwhere(ser % 3==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. How to extract items at given positions from a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "\n",
    "# Solution\n",
    "ser.take(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. How to stack two series vertically and horizontally ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "\n",
    "# Output\n",
    "# Vertical\n",
    "ser1.append(ser2)\n",
    "\n",
    "# Horizontal\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. How to get the positions of items of series A in another series B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 0, 8]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "\n",
    "# Solution 1\n",
    "[np.where(i == ser1)[0].tolist()[0] for i in ser2]\n",
    "\n",
    "# Solution 2\n",
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. How to compute the mean squared error on a truth and predicted series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.278198926194229"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "\n",
    "# Solution\n",
    "np.mean((truth-pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. How to convert the first character of each element in a series to uppercase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Ass?\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "# Solution 1\n",
    "ser.map(lambda x: x.title())\n",
    "\n",
    "# Solution 2\n",
    "ser.map(lambda x: x[0].upper() + x[1:])\n",
    "\n",
    "# Solution 3\n",
    "pd.Series([i.title() for i in ser])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. How to calculate the number of characters in each word in a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    4\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "# Solution\n",
    "ser.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. How to compute difference of differences between consequtive numbers of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
      "[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "# Solution\n",
    "print(ser.diff().tolist())\n",
    "print(ser.diff().diff().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. How to convert a series of date-strings to a timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse(x))\n",
    "\n",
    "# Solution 2\n",
    "pd.to_datetime(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. How to get the day of month, week number, day of year and day of week from a series of date strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1, 2, 3, 4, 5, 6]\n",
      "Week number:  [53, 5, 9, 14, 19, 23]\n",
      "Day number of year:  [1, 33, 63, 94, 125, 157]\n",
      "Day of week:  ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "# Solution\n",
    "from dateutil.parser import parse\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# day of month\n",
    "print(\"Date: \", ser_ts.dt.day.tolist())\n",
    "\n",
    "# week number\n",
    "print(\"Week number: \", ser_ts.dt.weekofyear.tolist())\n",
    "\n",
    "# day of year\n",
    "print(\"Day number of year: \", ser_ts.dt.dayofyear.tolist())\n",
    "\n",
    "# day of week\n",
    "print(\"Day of week: \", ser_ts.dt.weekday_name.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. How to convert year-month string to dates corresponding to the 4th day of the month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-04\n",
       "1   2011-02-04\n",
       "2   2012-03-04\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Input\n",
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "# Parse the date\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# Construct date string with date as 4\n",
    "ser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str') + '-' + '04'\n",
    "\n",
    "# Format it.\n",
    "[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]\n",
    "\n",
    "# Solution 2\n",
    "ser.map(lambda x: parse('04 ' + x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. How to filter words that contain atleast 2 vowels from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "\n",
    "# Solution\n",
    "from collections import Counter\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. How to filter valid emails from a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "\n",
    "# Solution 1 (as series of strings)\n",
    "import re\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "mask = emails.map(lambda x: bool(re.match(pattern, x)))\n",
    "emails[mask]\n",
    "\n",
    "# Solution 2 (as series of list)\n",
    "emails.str.findall(pattern, flags=re.IGNORECASE)\n",
    "\n",
    "# Solution 3 (as list)\n",
    "[x[0] for x in [re.findall(pattern, email) for email in emails] if len(x) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26. How to get the mean of a series grouped by another series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     2.500000\n",
       "banana    9.000000\n",
       "carrot    5.857143\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "\n",
    "# Solution\n",
    "weights.groupby(fruit).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27. How to compute the euclidean distance between two series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "\n",
    "# Solution \n",
    "sum((p - q)**2)**.5\n",
    "\n",
    "# Solution (using func)\n",
    "np.linalg.norm(p-q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28. How to find all the local maxima (or peaks) in a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "\n",
    "# Solution\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29. How to replace missing spaces in a string with the least frequent character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "b    3\n",
      "     3\n",
      "e    3\n",
      "a    2\n",
      "g    1\n",
      "c    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dbccdebcabedcgade'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "my_str = 'dbc deb abed gade'\n",
    "\n",
    "# Solution\n",
    "ser = pd.Series(list('dbc deb abed gade'))\n",
    "freq = ser.value_counts()\n",
    "print(freq)\n",
    "least_freq = freq.dropna().index[-1]\n",
    "\"\".join(ser.replace(' ', least_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    6\n",
       "2000-01-08    5\n",
       "2000-01-15    8\n",
       "2000-01-22    3\n",
       "2000-01-29    5\n",
       "2000-02-05    1\n",
       "2000-02-12    1\n",
       "2000-02-19    1\n",
       "2000-02-26    7\n",
       "2000-03-04    3\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02    10.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04     3.0\n",
       "2000-01-05     3.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     3.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series([1,10,3, np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "\n",
    "# Solution\n",
    "ser.resample('D').ffill()  # fill with previous value\n",
    "\n",
    "# Alternatives\n",
    "ser.resample('D').bfill()  # fill with next value\n",
    "ser.resample('D').bfill().ffill()  # fill next else prev value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32. How to compute the autocorrelations of a numeric series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46, 0.21, 0.38, 0.05, 0.2, 0.19, 0.25, 0.39, -0.4, -0.32]\n",
      "Lag having highest correlation:  1\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "\n",
    "# Solution\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 33. How to import only every nth row from a csv file to create a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  zn  indus chas    nox     rm   age     dis rad  tax ptratio  \\\n",
      "0  0.21977   0   6.91    0  0.448  5.602    62  6.0877   3  233    17.9   \n",
      "1   0.0686   0   2.89    0  0.445  7.416  62.5  3.4952   2  276      18   \n",
      "2  2.73397   0  19.58    0  0.871  5.597  94.9  1.5257   5  403    14.7   \n",
      "3   0.0315  95   1.47    0  0.403  6.975  15.3  7.6534   3  402      17   \n",
      "4  0.19073  22   5.86    0  0.431  6.718  17.5  7.8265   7  330    19.1   \n",
      "\n",
      "        b  lstat  medv  \n",
      "0   396.9   16.2  19.4  \n",
      "1   396.9   6.19  33.2  \n",
      "2  351.85  21.45  15.4  \n",
      "3   396.9   4.56  34.9  \n",
      "4  393.74   6.56  26.2  \n"
     ]
    }
   ],
   "source": [
    "# Solution 1: Use chunks and for-loop\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.DataFrame()\n",
    "for chunk in df:\n",
    "    df2 = df2.append(chunk.iloc[0,:])\n",
    "\n",
    "\n",
    "# Solution 2: Use chunks and list comprehension\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\n",
    "df2 = df2.transpose()\n",
    "\n",
    "# Solution 3: Use csv reader\n",
    "import csv          \n",
    "with open('BostonHousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i%50 == 0:\n",
    "            out.append(row)\n",
    "\n",
    "df2 = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 34. How to change column values when importing csv to a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  zn indus chas    nox     rm   age     dis rad  tax ptratio  \\\n",
      "0  0.00632  18  2.31    0  0.538  6.575  65.2    4.09   1  296    15.3   \n",
      "1  0.02731   0  7.07    0  0.469  6.421  78.9  4.9671   2  242    17.8   \n",
      "2  0.02729   0  7.07    0  0.469  7.185  61.1  4.9671   2  242    17.8   \n",
      "3  0.03237   0  2.18    0  0.458  6.998  45.8  6.0622   3  222    18.7   \n",
      "4  0.06905   0  2.18    0  0.458  7.147  54.2  6.0622   3  222    18.7   \n",
      "\n",
      "        b lstat  medv  \n",
      "0   396.9  4.98   Low  \n",
      "1   396.9  9.14   Low  \n",
      "2  392.83  4.03  High  \n",
      "3  394.63  2.94  High  \n",
      "4   396.9  5.33  High  \n"
     ]
    }
   ],
   "source": [
    "# Solution 1: Using converter parameter\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', \n",
    "                 converters={'medv': lambda x: 'High' if float(x) > 25 else 'Low'})\n",
    "\n",
    "\n",
    "# Solution 2: Using csv reader\n",
    "import csv\n",
    "with open('BostonHousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i > 0:\n",
    "            row[13] = 'High' if float(row[13]) > 25 else 'Low'\n",
    "        out.append(row)\n",
    "\n",
    "df = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 35. How to create a dataframe with rows as strides from a given series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = pd.Series(range(15))\n",
    "\n",
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 36. How to import only specified columns from a csv file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 27)\n",
      "Manufacturer           object\n",
      "Model                  object\n",
      "Type                   object\n",
      "Min.Price             float64\n",
      "Price                 float64\n",
      "Max.Price             float64\n",
      "MPG.city              float64\n",
      "MPG.highway           float64\n",
      "AirBags                object\n",
      "DriveTrain             object\n",
      "Cylinders              object\n",
      "EngineSize            float64\n",
      "Horsepower            float64\n",
      "RPM                   float64\n",
      "Rev.per.mile          float64\n",
      "Man.trans.avail        object\n",
      "Fuel.tank.capacity    float64\n",
      "Passengers            float64\n",
      "Length                float64\n",
      "Wheelbase             float64\n",
      "Width                 float64\n",
      "Turn.circle           float64\n",
      "Rear.seat.room        float64\n",
      "Luggage.room          float64\n",
      "Weight                float64\n",
      "Origin                 object\n",
      "Make                   object\n",
      "dtype: object\n",
      "float64    18\n",
      "object      9\n",
      "dtype: int64\n",
      "float64    18\n",
      "object      9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "#  number of rows and columns\n",
    "print(df.shape)\n",
    "\n",
    "# datatypes\n",
    "print(df.dtypes)\n",
    "\n",
    "# how many columns under each dtype\n",
    "print(df.get_dtype_counts())\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# summary statistics\n",
    "df_stats = df.describe()\n",
    "\n",
    "# numpy array \n",
    "df_arr = df.values\n",
    "\n",
    "# list\n",
    "df_list = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 38. How to extract the row and column number of a particular cell with given criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "# Get Manufacturer with highest price\n",
    "df.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']]\n",
    "\n",
    "# Get Row and Column number\n",
    "row, col = np.where(df.values == np.max(df.Price))\n",
    "\n",
    "# Get the value\n",
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]\n",
    "\n",
    "# Alternates\n",
    "df.at[row[0], 'Price']\n",
    "df.get_value(row[0], 'Price')\n",
    "\n",
    "# The difference between `iat` - `iloc` vs `at` - `loc` is:\n",
    "# `iat` snd `iloc` accepts row and column numbers. \n",
    "# Whereas `at` and `loc` accepts index and column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 39. How to rename a specific columns in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
      "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
      "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "# Step 1:\n",
    "df=df.rename(columns = {'Type':'CarType'})\n",
    "# or\n",
    "df.columns.values[2] = \"CarType\"\n",
    "\n",
    "# Step 2:\n",
    "df.columns = df.columns.map(lambda x: x.replace('.', '_'))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40. How to check if a dataframe has any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41. How to count the number of missing values in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Luggage.room'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "n_missings_each_col = df.apply(lambda x: x.isnull().sum())\n",
    "n_missings_each_col.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 42. How to replace missing values of multiple numeric columns with the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min.Price  Max.Price\n",
      "0  12.900000  18.800000\n",
      "1  29.200000  38.700000\n",
      "2  25.900000  32.300000\n",
      "3  17.118605  44.600000\n",
      "4  17.118605  21.459091\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "df_out = df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x: x.fillna(x.mean()))\n",
    "print(df_out.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43. How to use apply function on existing columns with global variables as additional arguments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\n",
    "df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44. How to select a specific column from a dataframe as a dataframe instead of a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "# Solution\n",
    "type(df[['a']])\n",
    "type(df.loc[:, ['a']])\n",
    "type(df.iloc[:, [0]])\n",
    "\n",
    "# Alternately the following returns a Series\n",
    "type(df.a)\n",
    "type(df['a'])\n",
    "type(df.loc[:, 'a'])\n",
    "type(df.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 45. How to change the order of columns of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "# Solution Q1\n",
    "df[list('cbade')]\n",
    "\n",
    "# Solution Q2 - No hard coding\n",
    "def switch_columns(df, col1=None, col2=None):\n",
    "    colnames = df.columns.tolist()\n",
    "    i1, i2 = colnames.index(col1), colnames.index(col2)\n",
    "    colnames[i2], colnames[i1] = colnames[i1], colnames[i2]\n",
    "    return df[colnames]\n",
    "\n",
    "df1 = switch_columns(df, 'a', 'c')\n",
    "\n",
    "# Solution Q3\n",
    "df[sorted(df.columns)]\n",
    "# or\n",
    "df.sort_index(axis=1, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46. How to set the number of rows and columns displayed in the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "# df\n",
    "\n",
    "# Show all available options\n",
    "# pd.describe_option()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 47. How to format or suppress scientific notations in a pandas dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random\n",
      "0  0.0000\n",
      "1  0.0001\n",
      "2  0.0000\n",
      "3  0.0000\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
    "\n",
    "# Solution 1: Rounding\n",
    "df.round(4)\n",
    "\n",
    "# Solution 2: Use apply to change format\n",
    "df.apply(lambda x: '%.4f' % x, axis=1)\n",
    "# or\n",
    "df.applymap(lambda x: '%.4f' % x)\n",
    "\n",
    "# Solution 3: Use set_option\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "# Solution 4: Assign display.float_format\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "print(df)\n",
    "\n",
    "# Reset/undo float formatting\n",
    "pd.options.display.float_format = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48. How to format all the values in a dataframe as percentages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_8f04a5b4_09a8_11e9_9ba3_2c4d54d7919f\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >random</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_8f04a5b4_09a8_11e9_9ba3_2c4d54d7919flevel0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_8f04a5b4_09a8_11e9_9ba3_2c4d54d7919frow0_col0\" class=\"data row0 col0\" >7.08%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8f04a5b4_09a8_11e9_9ba3_2c4d54d7919flevel0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_8f04a5b4_09a8_11e9_9ba3_2c4d54d7919frow1_col0\" class=\"data row1 col0\" >87.87%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8f04a5b4_09a8_11e9_9ba3_2c4d54d7919flevel0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_8f04a5b4_09a8_11e9_9ba3_2c4d54d7919frow2_col0\" class=\"data row2 col0\" >10.21%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_8f04a5b4_09a8_11e9_9ba3_2c4d54d7919flevel0_row3\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_8f04a5b4_09a8_11e9_9ba3_2c4d54d7919frow3_col0\" class=\"data row3 col0\" >44.80%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26e27c75c88>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "\n",
    "# Solution\n",
    "out = df.style.format({\n",
    "    'random': '{0:.2%}'.format,\n",
    "})\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 49. How to filter every nth row in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type\n",
      "0         Acura  Integra    Small\n",
      "20     Chrysler  LeBaron  Compact\n",
      "40        Honda  Prelude   Sporty\n",
      "60      Mercury   Cougar  Midsize\n",
      "80       Subaru   Loyale    Small\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "print(df.iloc[::20, :][['Manufacturer', 'Model', 'Type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50. How to create a primary key index by combining relevant columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n",
    "\n",
    "# Solution\n",
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing')\n",
    "df.index = df.Manufacturer + '_' + df.Model + '_' + df.Type\n",
    "print(df.index.is_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 51. How to get the row number of the nth largest value in a column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1, 30, 30).reshape(10,-1), columns=list('abc'))\n",
    "\n",
    "# Solution\n",
    "n = 5\n",
    "df['a'].argsort()[::-1][n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52. How to find the position of the nth largest value greater than a given value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ser:  [5, 45, 68, 85, 80, 51, 7, 72, 60, 50, 8, 29, 65, 59, 41] mean:  48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.randint(1, 100, 15))\n",
    "\n",
    "# Solution\n",
    "print('ser: ', ser.tolist(), 'mean: ', round(ser.mean()))\n",
    "np.argwhere(ser > ser.mean())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53. How to get the last n rows of a dataframe with row sum > 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n",
    "\n",
    "# Solution\n",
    "# print row sums\n",
    "rowsums = df.apply(np.sum, axis=1)\n",
    "\n",
    "# last two rows with row sum greater than 100\n",
    "last_two_rows = df.iloc[np.where(rowsums > 100)[0][-2:], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54. How to find and cap outliers from a series or dataframe column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 %ile:  0.016049294076965887 | 0.95 %ile:  63.876672220183934\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.logspace(-2, 2, 30))\n",
    "\n",
    "# Solution\n",
    "def cap_outliers(ser, low_perc, high_perc):\n",
    "    low, high = ser.quantile([low_perc, high_perc])\n",
    "    print(low_perc, '%ile: ', low, '|', high_perc, '%ile: ', high)\n",
    "    ser[ser < low] = low\n",
    "    ser[ser > high] = high\n",
    "    return(ser)\n",
    "\n",
    "capped_ser = cap_outliers(ser, .05, .95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55. How to reshape a dataframe to the largest possible square after removing the negative values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4   5   6   7   8   9\n",
      "0  34  21  30 -18  43   7   2 -10  30  13\n",
      "1  34  -6 -20  39   5  -2  -5  -9  35  33\n",
      "2   8  16  -6  31  40 -13  24  39  32  32\n",
      "3  24  32   8 -15 -18  19  29  41  18  44\n",
      "4   5  21   5  -4  39  33 -12   0  26  23\n",
      "5   6  38  21  11   4 -14   9 -11 -11   3\n",
      "6  43  -1 -20 -16  18  27  39   7  35 -11\n",
      "7  42  -9   5  31  16  28  -8 -12 -11  34\n",
      "8   3 -10  48  42  18 -16 -10   4  -6  35\n",
      "9  14  -5  19 -12  -7   6  17  16  35  13\n",
      "[[34. 21. 30. 43.  7. 30. 13. 34.]\n",
      " [39.  5. 35. 33.  8. 16. 31. 40.]\n",
      " [24. 39. 32. 32. 24. 32.  8. 19.]\n",
      " [29. 41. 18. 44.  5. 21.  5. 39.]\n",
      " [33. 26. 23.  6. 38. 21. 11.  9.]\n",
      " [43. 18. 27. 39.  7. 35. 42.  5.]\n",
      " [31. 16. 28. 34. 48. 42. 18.  4.]\n",
      " [35. 14. 19.  6. 17. 16. 35. 13.]]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(-20, 50, 100).reshape(10,-1))\n",
    "print(df)\n",
    "\n",
    "# Solution\n",
    "# Step 1: remove negative values from arr\n",
    "arr = df[df > 0].values.flatten()\n",
    "arr_qualified = arr[~np.isnan(arr)]\n",
    "\n",
    "# Step 2: find side-length of largest possible square\n",
    "n = int(np.floor(arr_qualified.shape[0]**.5))\n",
    "\n",
    "# Step 3: Take top n^2 items without changing positions\n",
    "top_indexes = np.argsort(arr_qualified)[::-1]\n",
    "output = np.take(arr_qualified, sorted(top_indexes[:n**2])).reshape(n, -1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56. How to swap two rows of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "0   0   1   2   3   4\n",
      "1  10  11  12  13  14\n",
      "2   5   6   7   8   9\n",
      "3  15  16  17  18  19\n",
      "4  20  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "\n",
    "# Solution\n",
    "def swap_rows(df, i1, i2):\n",
    "    a, b = df.iloc[i1, :].copy(), df.iloc[i2, :].copy()\n",
    "    df.iloc[i1, :], df.iloc[i2, :] = b, a\n",
    "    return df\n",
    "\n",
    "print(swap_rows(df, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57. How to reverse the rows of a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4\n",
      "4  20  21  22  23  24\n",
      "3  15  16  17  18  19\n",
      "2  10  11  12  13  14\n",
      "1   5   6   7   8   9\n",
      "0   0   1   2   3   4\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(25).reshape(5, -1))\n",
    "\n",
    "# Solution 1\n",
    "df.iloc[::-1, :]\n",
    "\n",
    "# Solution 2\n",
    "print(df.loc[df.index[::-1], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 58. How to create one-hot encodings of a categorical variable (dummy variables)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  5  10  15  20   b   c   d   e\n",
      "0  1  0   0   0   0   1   2   3   4\n",
      "1  0  1   0   0   0   6   7   8   9\n",
      "2  0  0   1   0   0  11  12  13  14\n",
      "3  0  0   0   1   0  16  17  18  19\n",
      "4  0  0   0   0   1  21  22  23  24\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(25).reshape(5,-1), columns=list('abcde'))\n",
    "\n",
    "# Solution\n",
    "df_onehot = pd.concat([pd.get_dummies(df['a']), df[list('bcde')]], axis=1)\n",
    "print(df_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 59. Which column contains the highest number of row-wise maximum values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column with highest row maxes:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:52: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1))\n",
    "\n",
    "# Solution\n",
    "print('Column with highest row maxes: ', df.apply(np.argmax, axis=1).value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 60. How to create a new column that contains the row number of nearest column by euclidean distance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100, 40).reshape(10, -1), columns=list('pqrs'), index=list('abcdefghij'))\n",
    "\n",
    "# Solution\n",
    "import numpy as np\n",
    "\n",
    "# init outputs\n",
    "nearest_rows = []\n",
    "nearest_distance = []\n",
    "\n",
    "# iterate rows.\n",
    "for i, row in df.iterrows():\n",
    "    curr = row\n",
    "    rest = df.drop(i)\n",
    "    e_dists = {}  # init dict to store euclidean dists for current row.\n",
    "    # iterate rest of rows for current row\n",
    "    for j, contestant in rest.iterrows():\n",
    "        # compute euclidean dist and update e_dists\n",
    "        e_dists.update({j: round(np.linalg.norm(curr.values - contestant.values))})\n",
    "    # update nearest row to current row and the distance value\n",
    "    nearest_rows.append(max(e_dists, key=e_dists.get))\n",
    "    nearest_distance.append(max(e_dists.values()))\n",
    "\n",
    "df['nearest_row'] = nearest_rows\n",
    "df['dist'] = nearest_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 61. How to know the maximum possible correlation value of each column against other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Correlation possible for each column:  [0.72 0.61 0.68 0.68 0.64 0.72 0.63 0.68 0.68 0.68]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1), columns=list('pqrstuvwxy'), index=list('abcdefgh'))\n",
    "df\n",
    "\n",
    "# Solution\n",
    "abs_corrmat = np.abs(df.corr())\n",
    "max_corr = abs_corrmat.apply(lambda x: sorted(x)[-2])\n",
    "print('Maximum Correlation possible for each column: ', np.round(max_corr.tolist(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 62. How to create a column containing the minimum by maximum of each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution 1\n",
    "min_by_max = df.apply(lambda x: np.min(x)/np.max(x), axis=1)\n",
    "\n",
    "# Solution 2\n",
    "min_by_max = np.min(df, axis=1)/np.max(df, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 63. How to create a column that contains the penultimate value in each row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1   2   3   4     ...        6   7   8   9  penultimate\n",
      "0  68  47  95  36   4     ...       91  74  83  25           91\n",
      "1  49  69   9  81  14     ...       79  11  53  62           81\n",
      "2  96   5  65  92  97     ...       10  23   1  76           96\n",
      "3  35  49  57  14  65     ...       96  79  53  51           88\n",
      "4  88  47  60  14  78     ...       23  75  80  13           80\n",
      "5  59  21  81  57  58     ...       43   2  99  96           96\n",
      "6  14  83  92   1  57     ...       97  34  13  22           92\n",
      "7  82  89  95  55   2     ...       68  65  78  79           89\n",
      "\n",
      "[8 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution\n",
    "out = df.apply(lambda x: x.sort_values().unique()[-2], axis=1)\n",
    "df['penultimate'] = out\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 64. How to normalize all columns in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution Q1\n",
      "       0     1     2     3     4     5     6     7     8     9\n",
      "0 -1.18  1.75 -0.01 -0.54 -0.99  1.04  1.56 -0.09  0.03  1.16\n",
      "1 -1.07 -0.32  0.59  1.05  1.13 -0.27  1.52  0.60  2.00  0.40\n",
      "2 -0.04 -0.11 -0.82 -0.33 -1.47  0.76 -0.20 -1.11 -0.90 -1.04\n",
      "3  0.56 -0.91 -0.92 -0.12  0.01  0.11 -0.51 -0.57 -0.10  0.94\n",
      "4 -0.69  1.33  1.30  1.40 -0.59 -0.30 -1.10  1.44 -0.48 -1.40\n",
      "5 -0.08 -0.98  1.40 -1.00  0.49 -1.21 -0.15  0.81  0.91 -0.53\n",
      "6  0.72 -0.35 -1.13  0.87  0.01 -1.43 -0.78 -1.47 -0.90 -0.53\n",
      "7  1.78 -0.39 -0.42 -1.32  1.41  1.29 -0.33  0.39 -0.56  1.00\n",
      "Solution Q2\n",
      "       0     1     2     3     4     5     6     7     8     9\n",
      "0  1.00  0.00  0.56  0.71  0.83  0.09  0.00  0.53  0.68  0.00\n",
      "1  0.96  0.76  0.32  0.13  0.10  0.57  0.02  0.29  0.00  0.30\n",
      "2  0.62  0.68  0.88  0.64  1.00  0.20  0.66  0.88  1.00  0.86\n",
      "3  0.41  0.97  0.92  0.56  0.49  0.44  0.78  0.69  0.72  0.09\n",
      "4  0.83  0.15  0.04  0.00  0.69  0.59  1.00  0.00  0.86  1.00\n",
      "5  0.63  1.00  0.00  0.88  0.32  0.92  0.64  0.22  0.38  0.66\n",
      "6  0.36  0.77  1.00  0.19  0.49  1.00  0.88  1.00  1.00  0.66\n",
      "7  0.00  0.78  0.72  1.00  0.00  0.00  0.71  0.36  0.88  0.07\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution Q1\n",
    "out1 = df.apply(lambda x: ((x - x.mean())/x.std()).round(2))\n",
    "print('Solution Q1\\n',out1)\n",
    "\n",
    "# Solution Q2\n",
    "out2 = df.apply(lambda x: ((x.max() - x)/(x.max() - x.min())).round(2))\n",
    "print('Solution Q2\\n', out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 65. How to compute the correlation of each row with the suceeding row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.29, 0.27, 0.15, 0.12, -0.19, 0.06, -0.32]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 80).reshape(8, -1))\n",
    "\n",
    "# Solution\n",
    "[df.iloc[i].corr(df.iloc[i+1]).round(2) for i in range(df.shape[0])[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 66. How to replace both the diagonals of dataframe with 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1,100, 100).reshape(10, -1))\n",
    "\n",
    "# Solution\n",
    "for i in range(df.shape[0]):\n",
    "    df.iat[i, i] = 0\n",
    "    df.iat[df.shape[0]-i-1, i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 67. How to get the particular group of a groupby dataframe by key?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    col1      col2  col3\n",
      "0  apple  0.269764     1\n",
      "3  apple  0.972532    14\n",
      "6  apple  0.669241    10\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame({'col1': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'col2': np.random.rand(9),\n",
    "                   'col3': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df_grouped = df.groupby(['col1'])\n",
    "\n",
    "# Solution 1\n",
    "df_grouped.get_group('apple')\n",
    "\n",
    "# Solution 2\n",
    "for i, dff in df_grouped:\n",
    "    if i == 'apple':\n",
    "        print(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 68. How to get the n’th largest value of a column when grouped by another column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit     taste  price\n",
      "0   apple  0.870908      5\n",
      "1  banana  0.494638     12\n",
      "2  orange  0.288171     12\n",
      "3   apple  0.617630     10\n",
      "4  banana  0.765468      7\n",
      "5  orange  0.736031     10\n",
      "6   apple  0.132091      6\n",
      "7  banana  0.044397     10\n",
      "8  orange  0.605437     10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49463813115013755"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'taste': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Solution\n",
    "df_grpd = df['taste'].groupby(df.fruit)\n",
    "df_grpd.get_group('banana').sort_values().iloc[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 69. How to compute grouped mean on pandas dataframe and keep the grouped column as another column (not index)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit     price\n",
      "0   apple  3.000000\n",
      "1  banana  5.666667\n",
      "2  orange  2.666667\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                   'rating': np.random.rand(9),\n",
    "                   'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "# Solution\n",
    "out = df.groupby('fruit', as_index=False)['price'].mean()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70. How to join two dataframes by 2 columns so they have only the common rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-8bac088b685c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Solution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fruit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pazham'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pounds'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_right'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     58\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    548\u001b[0m         (self.left_join_keys,\n\u001b[0;32m    549\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    854\u001b[0m                             right_keys.append(\n\u001b[0;32m    855\u001b[0m                                 right._get_label_or_level_values(\n\u001b[1;32m--> 856\u001b[1;33m                                     rk, stacklevel=stacklevel))\n\u001b[0m\u001b[0;32m    857\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis, stacklevel)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pounds'"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 9)})\n",
    "\n",
    "df2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'kilo': ['high', 'low'] * 3,\n",
    "                    'price': np.random.randint(0, 15, 6)})\n",
    "\n",
    "# Solution\n",
    "pd.merge(df1, df2, how='inner', left_on=['fruit', 'weight'], right_on=['pazham', 'pounds'], suffixes=['_left', '_right'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71. How to remove rows from a dataframe that are present in another dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fruit  weight  price\n",
      "2  banana     low      2\n",
      "3   apple    high      3\n",
      "4  orange  medium      4\n",
      "5  banana     low      5\n",
      "6   apple    high      6\n",
      "7  orange  medium      7\n",
      "8  banana     low      8\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df1 = pd.DataFrame({'fruit': ['apple', 'orange', 'banana'] * 3,\n",
    "                    'weight': ['high', 'medium', 'low'] * 3,\n",
    "                    'price': np.arange(9)})\n",
    "\n",
    "df2 = pd.DataFrame({'fruit': ['apple', 'orange', 'pine'] * 2,\n",
    "                    'weight': ['high', 'medium'] * 3,\n",
    "                    'price': np.arange(6)})\n",
    "\n",
    "\n",
    "# Solution\n",
    "print(df1[~df1.isin(df2).all(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72. How to get the positions where values of two columns match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 9], dtype=int64),)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame({'fruit1': np.random.choice(['apple', 'orange', 'banana'], 10),\n",
    "                    'fruit2': np.random.choice(['apple', 'orange', 'banana'], 10)})\n",
    "\n",
    "# Solution\n",
    "np.where(df.fruit1 == df.fruit2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73. How to create lags and leads of a column in a dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   b   c   d  a_lag1  b_lead1\n",
      "0  84  77  71  97     NaN     89.0\n",
      "1  67  89  78  77    84.0     95.0\n",
      "2  45  95  55  47    67.0     11.0\n",
      "3  22  11  33  85    45.0     42.0\n",
      "4  70  42   2  44    22.0      NaN\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1, 100, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "# Solution\n",
    "df['a_lag1'] = df['a'].shift(1)\n",
    "df['b_lead1'] = df['b'].shift(-1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 74. How to get the frequency of unique values in the entire dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    4\n",
       "2    4\n",
       "9    3\n",
       "6    3\n",
       "3    3\n",
       "8    1\n",
       "5    1\n",
       "1    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.randint(1, 10, 20).reshape(-1, 4), columns = list('abcd'))\n",
    "\n",
    "# Solution\n",
    "pd.value_counts(df.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 75. How to split a text column into two separate columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 STD            City    State\n",
      "1  33   Kolkata    West Bengal\n",
      "2  44    Chennai    Tamil Nadu\n",
      "3  40   Hyderabad    Telengana\n",
      "4  80   Bangalore    Karnataka\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame([\"STD, City    State\",\n",
    "\"33, Kolkata    West Bengal\",\n",
    "\"44, Chennai    Tamil Nadu\",\n",
    "\"40, Hyderabad    Telengana\",\n",
    "\"80, Bangalore    Karnataka\"], columns=['row'])\n",
    "\n",
    "# Solution\n",
    "df_out = df.row.str.split(',|\\t', expand=True)\n",
    "\n",
    "# Make first row as header\n",
    "new_header = df_out.iloc[0]\n",
    "df_out = df_out[1:]\n",
    "df_out.columns = new_header\n",
    "print(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
